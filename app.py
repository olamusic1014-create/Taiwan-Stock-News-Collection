import streamlit as st
import asyncio
from playwright.async_api import async_playwright
import time
import random
import sys
import xml.etree.ElementTree as ET
import os
import subprocess
import re
import json

# ===========================
# ğŸ› ï¸ è‡ªå‹•å®‰è£ requests
# ===========================
try:
    import requests
except ImportError:
    subprocess.run([sys.executable, "-m", "pip", "install", "requests"], check=True)
    import requests

# ===========================
# 0. ç’°å¢ƒæº–å‚™
# ===========================
try:
    subprocess.run(["playwright", "install", "chromium"], check=True)
except Exception:
    pass

if sys.platform.startswith("win"):
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

# ===========================
# ğŸ” è³‡å®‰æ ¸å¿ƒ
# ===========================
SYSTEM_API_KEY = st.secrets.get("GEMINI_API_KEY", None)

# ===========================
# 1. è‚¡ç¥¨è³‡æ–™åº«
# ===========================
BASE_STOCKS = {
    "å°ç©é›»": "2330", "è¯é›»": "2303", "é´»æµ·": "2317", "è¯ç™¼ç§‘": "2454", "é•·æ¦®": "2603",
    "é™½æ˜": "2609", "è¬æµ·": "2615", "ä¸­é‹¼": "2002", "ä¸­é´»": "2014", "å°å¡‘": "1301",
    "å—äº": "1303", "å°åŒ–": "1326", "å°å¡‘åŒ–": "6505", "åœ‹æ³°é‡‘": "2882", "å¯Œé‚¦é‡‘": "2881",
    "ä¸­ä¿¡é‡‘": "2891", "ç‰å±±é‡‘": "2884", "å…ƒå¤§é‡‘": "2885", "å…†è±é‡‘": "2886", "å°æ³¥": "1101",
    "ç·¯å‰µ": "3231", "å»£é”": "2382", "è‹±æ¥­é”": "2356", "ä»å¯¶": "2324", "å’Œç¢©": "4938",
    "æŠ€å˜‰": "2376", "å¾®æ˜Ÿ": "2377", "è¯ç¢©": "2357", "å®ç¢": "2353", "å…‰å¯¶ç§‘": "2301",
    "ç¾¤å‰µ": "3481", "å‹é”": "2409", "å½©æ™¶": "6116", "è¯è© ": "3034", "ç‘æ˜±": "2379",
    "å°é”é›»": "2308", "æ—¥æœˆå…‰": "3711", "åŠ›ç©é›»": "6770", "ä¸–ç•Œ": "5347", "å…ƒå¤ª": "8069",
    "æ™ºåŸ": "3035", "å‰µæ„": "3443", "ä¸–èŠ¯": "3661", "æ„›æ™®": "6531", "ç¥¥ç¢©": "5269",
    "é•·æ¦®èˆª": "2618", "è¯èˆª": "2610", "é«˜éµ": "2633", "è£•éš†": "2201", "å’Œæ³°è»Š": "2207",
    "çµ±ä¸€è¶…": "2912", "å…¨å®¶": "5903", "ä¸­è¯é›»": "2412", "å°ç£å¤§": "3045", "é å‚³": "4904",
    "é–‹ç™¼é‡‘": "2883", "æ–°å…‰é‡‘": "2888", "æ°¸è±é‡‘": "2890", "å°æ–°é‡‘": "2887", "åˆåº«é‡‘": "5880",
    "ç¬¬ä¸€é‡‘": "2892", "è¯å—é‡‘": "2880", "å½°éŠ€": "2801", "è‡ºä¼éŠ€": "2834", "ä¸Šæµ·å•†éŠ€": "5876",
    "å…ƒå¤§å°ç£50": "0050", "å…ƒå¤§é«˜è‚¡æ¯": "0056", "åœ‹æ³°æ°¸çºŒé«˜è‚¡æ¯": "00878", "å¾©è¯å°ç£ç§‘æŠ€å„ªæ¯": "00929",
    "ç¾¤ç›Šå°ç£ç²¾é¸é«˜æ¯": "00919", "å…ƒå¤§ç¾å‚µ20å¹´": "00679B", "çµ±ä¸€å°ç£é«˜æ¯å‹•èƒ½": "00939", "å…ƒå¤§å°ç£åƒ¹å€¼é«˜æ¯": "00940"
}

# ===========================
# 2. çˆ¬èŸ²æ¨¡çµ„
# ===========================
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"
]
def get_ua(): return random.choice(USER_AGENTS)

async def sync_market_data():
    full_stock_dict = BASE_STOCKS.copy()
    try:
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            context = await browser.new_context(user_agent=get_ua())
            try:
                api_url = "https://scanner.tradingview.com/taiwan/scan"
                payload = {
                    "columns": ["name", "description", "volume"],
                    "ignore_unknown_fields": False,
                    "options": {"lang": "zh_TW"},
                    "range": [0, 1500],
                    "sort": {"sortBy": "volume", "sortOrder": "desc"},
                    "symbols": {"query": {"types": []}, "tickers": []},
                    "filter": [{"left": "type", "operation": "in_range", "right": ["stock", "dr", "fund"]}]
                }
                resp = requests.post(api_url, json=payload, timeout=5)
                if resp.status_code == 200:
                    data = resp.json()
                    for item in data.get('data', []):
                        code = item['d'][0]
                        name = item['d'][1].replace("KY", "").strip()
                        full_stock_dict[name] = code
            except: pass
            await browser.close()
    except Exception: pass
    return full_stock_dict, len(full_stock_dict)

async def resolve_stock_info(user_input, stock_dict):
    clean_input = user_input.strip().upper()
    for name, code in stock_dict.items():
        if clean_input == name or clean_input == code: return code, name
    for name, code in stock_dict.items():
        if clean_input in name: return code, name
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        try:
            page = await browser.new_page(user_agent=get_ua())
            encoded = requests.utils.quote(clean_input)
            await page.goto(f"https://tw.stock.yahoo.com/search?p={encoded}", timeout=8000)
            link = page.locator("a[href*='/quote/']").first
            if await link.count() > 0:
                text = await link.inner_text()
                href = await link.get_attribute("href")
                match = re.search(r"(\d{4,6})", href)
                if match:
                    code = match.group(1)
                    name = text.split("\n")[0].strip()
                    if name == code or not name: name = clean_input
                    return code, name
        except: pass
        finally: await browser.close()
    return None, None

async def fetch_google_rss(stock_code, site_domain, source_name):
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(user_agent=get_ua())
        page = await context.new_page()
        try:
            rss_url = f"https://news.google.com/rss/search?q={stock_code}+site:{site_domain}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
            response = await page.goto(rss_url, timeout=20000, wait_until="commit")
            xml_content = await response.text()
            root = ET.fromstring(xml_content)
            data = []
            for item in root.findall('.//item'):
                title = item.find('title').text
                desc_html = item.find('description').text if item.find('description') is not None else ""
                desc_clean = re.sub(r'<[^>]+>', '', desc_html)
                clean_title = title.split(" - ")[0]
                if len(clean_title) > 4: 
                    data.append({"title": clean_title, "snippet": desc_clean[:200], "source": source_name})
            return data[:5]
        except: return []
        finally: await browser.close()

async def scrape_anue(stock_code):
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(user_agent=get_ua())
        page = await context.new_page()
        try:
            await page.goto(f"https://www.cnyes.com/search/news?q={stock_code}", timeout=15000, wait_until="commit")
            await page.wait_for_timeout(1500)
            titles = await page.locator('h3, h2').all_inner_texts()
            return [{"title": t, "snippet": t, "source": "é‰…äº¨ç¶²"} for t in titles if len(t) > 6][:5]
        except: return []
        finally: await browser.close()

async def scrape_yahoo(stock_code):
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(user_agent=get_ua())
        page = await context.new_page()
        try:
            await page.goto(f"https://tw.stock.yahoo.com/quote/{stock_code}.TW/news", timeout=20000, wait_until="domcontentloaded")
            await page.wait_for_timeout(1500)
            items = await page.locator('#YDC-Stream li').all()
            data = []
            for item in items[:5]:
                try:
                    t_el = item.locator('h3')
                    if await t_el.count() > 0:
                        title = await t_el.inner_text()
                        desc_el = item.locator('p')
                        snippet = await desc_el.inner_text() if await desc_el.count() > 0 else title
                        data.append({"title": title, "snippet": snippet, "source": "Yahoo"})
                except: pass
            return data
        except: return []
        finally: await browser.close()

async def scrape_udn(c): return await fetch_google_rss(c, "money.udn.com", "ç¶“æ¿Ÿæ—¥å ±")
async def scrape_ltn(c): return await fetch_google_rss(c, "ec.ltn.com.tw", "è‡ªç”±è²¡ç¶“")
async def scrape_ctee(c): return await fetch_google_rss(c, "ctee.com.tw", "å·¥å•†æ™‚å ±")
async def scrape_chinatimes(c): return await fetch_google_rss(c, "chinatimes.com", "ä¸­æ™‚æ–°è")
async def scrape_ettoday(c): return await fetch_google_rss(c, "ettoday.net", "ETtoday")
async def scrape_tvbs(c): return await fetch_google_rss(c, "news.tvbs.com.tw", "TVBSæ–°è")
async def scrape_businesstoday(c): return await fetch_google_rss(c, "businesstoday.com.tw", "ä»Šå‘¨åˆŠ")
async def scrape_wealth(c): return await fetch_google_rss(c, "wealth.com.tw", "è²¡è¨Š")
async def scrape_storm(c): return await fetch_google_rss(c, "storm.mg", "é¢¨å‚³åª’")

# ===========================
# 3. AI è©•åˆ†æ ¸å¿ƒ (Timeout ä¿®æ­£)
# ===========================
def get_available_model(api_key):
    try:
        url = f"https://generativelanguage.googleapis.com/v1beta/models?key={api_key}"
        response = requests.get(url, timeout=5)
        
        if response.status_code == 200:
            data = response.json()
            models = data.get('models', [])
            
            priority_list = ['models/gemini-1.5-flash', 'models/gemini-1.5-pro', 'models/gemini-1.0-pro', 'models/gemini-pro']
            
            for p_model in priority_list:
                for m in models:
                    if m['name'] == p_model and 'generateContent' in m['supportedGenerationMethods']:
                        return m['name']
            
            for m in models:
                if 'generateContent' in m['supportedGenerationMethods']:
                    return m['name']
    except Exception:
        pass
    return None

def analyze_with_gemini_requests(api_key, stock_name, news_data):
    model_name = get_available_model(api_key)
    if not model_name: model_name = "models/gemini-pro"
        
    news_text = ""
    for i, news in enumerate(news_data):
        news_text += f"{i+1}. [{news['source']}] {news['title']}\n   æ‘˜è¦: {news['snippet']}\n"

    prompt = f"""
    ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è¯çˆ¾è¡—è‚¡ç¥¨åˆ†æå¸«ã€‚è«‹é–±è®€ä»¥ä¸‹é—œæ–¼ã€Œ{stock_name}ã€çš„å°ç£è²¡ç¶“æ–°èæ‘˜è¦ï¼Œä¸¦é€²è¡Œç¶œåˆæƒ…ç·’åˆ†æã€‚
    
    æ–°èåˆ—è¡¨ï¼š
    {news_text}

    è«‹è¼¸å‡ºä»¥ä¸‹æ ¼å¼çš„å ±å‘Š (è«‹ç”¨ç¹é«”ä¸­æ–‡)ï¼š
    1. **æƒ…ç·’åˆ†æ•¸ (0-100)**: (0æ˜¯æ¥µåº¦ææ…Œ/åˆ©ç©ºï¼Œ50æ˜¯ä¸­ç«‹ï¼Œ100æ˜¯æ¥µåº¦æ¨‚è§€/åˆ©å¤š)ã€‚è«‹ç›´æ¥çµ¦å‡ºä¸€å€‹æ•¸å­—ã€‚
    2. **å¸‚å ´æ°£æ°›**: (ä¾‹å¦‚ï¼šåå¤šã€è§€æœ›ã€ä¸»åŠ›å‡ºè²¨ã€åˆ©å¤šå‡ºç›¡ç­‰)ã€‚
    3. **é—œéµæ‘˜è¦**: è«‹ç¸½çµé€™å¹¾å‰‡æ–°èçš„æ ¸å¿ƒé‡é»ï¼Œä¸è¦é€æ¢åˆ—å‡ºï¼Œè«‹èæœƒè²«é€šã€‚
    4. **å¤šç©ºåˆ†æ**: ç°¡å–®åˆ—å‡ºåˆ©å¤šå› ç´ èˆ‡åˆ©ç©ºå› ç´ ã€‚

    è¼¸å‡ºç¯„ä¾‹æ ¼å¼ï¼š
    SCORE: 75
    LEVEL: æ¨‚è§€åå¤š
    SUMMARY: ...
    ANALYSIS: ...
    """

    try:
        url = f"https://generativelanguage.googleapis.com/v1beta/{model_name}:generateContent?key={api_key}"
        headers = {'Content-Type': 'application/json'}
        payload = {
            "contents": [{"parts": [{"text": prompt}]}]
        }
        
        # âš ï¸ é€™è£¡æ”¹ç‚º 60 ç§’ï¼Œçµ¦ AI è¶³å¤ æ™‚é–“
        response = requests.post(url, headers=headers, json=payload, timeout=60)
        
        if response.status_code == 200:
            result = response.json()
            if 'candidates' in result and len(result['candidates']) > 0:
                content = result['candidates'][0]['content']['parts'][0]['text']
                score_match = re.search(r"SCORE:\s*(\d+)", content)
                score = int(score_match.group(1)) if score_match else 50
                return score, content, model_name
        else:
            return None, f"Error {response.status_code}: {response.text}", model_name

    except Exception as e:
        return None, str(e), model_name

    return None, "æœªçŸ¥éŒ¯èª¤", model_name

def calculate_score_keyword(news_list, source_name):
    if not news_list: return 0, []
    positive = ["ä¸Šæ¼²", "é£†", "å‰µé«˜", "è²·è¶…", "å¼·å‹¢", "è¶…é æœŸ", "å–å¾—", "è¶…è¶Š", "åˆ©å¤š", "æˆé•·", "æ”¶ç›Š", "å™´", "æ¼²åœ", "æ—º", "æ”»é ‚", "å—æƒ ", "çœ‹å¥½", "ç¿»ç´…", "é©šè‰·", "AI", "æ“´ç”¢", "å…ˆé€²", "å‹•èƒ½", "ç™¼å¨", "é ˜å…ˆ", "æ¶å–®", "å­£å¢", "å¹´å¢", "æ¨‚è§€", "å›æº«", "å¸ƒå±€", "åˆ©æ½¤", "å¤§æ¼²", "å®Œå‹"]
    negative = ["ä¸‹è·Œ", "è³£", "ç ", "è§€æœ›", "ä¿å®ˆ", "ä¸å¦‚", "é‡æŒ«", "å¤–è³‡è³£", "ç¸®æ¸›", "å´©", "è·Œåœ", "ç–²è»Ÿ", "åˆ©ç©º", "ä¿®æ­£", "èª¿ç¯€", "å»¶å¾Œ", "è¡°é€€", "ç¿»é»‘", "ç¤ºè­¦", "é‡æ®º", "ä¸å¦‚é æœŸ", "è£å“¡", "è™§æ", "å¤§è·Œ", "é‡æŒ«", "éš±æ†‚", "åˆ©ç©º"]
    score = 50; reasons = []
    for news in news_list:
        content = news['title'] + " " + news.get('snippet', "")
        hit = False
        for w in positive: 
            if w in content: score += 12; reasons.append(w); hit = True
        for w in negative: 
            if w in content: score -= 12; reasons.append(w); hit = True
        if not hit and len(content) > 10: score += 2
    return max(0, min(100, score)), list(set(reasons))

async def run_analysis(stock_code):
    return await asyncio.gather(
        scrape_anue(stock_code), scrape_yahoo(stock_code), scrape_udn(stock_code),
        scrape_ltn(stock_code), scrape_ctee(stock_code), scrape_chinatimes(stock_code),
        scrape_ettoday(stock_code), scrape_tvbs(stock_code), scrape_businesstoday(stock_code),
        scrape_wealth(stock_code), scrape_storm(stock_code)
    )

# ===========================
# 4. Streamlit ä»‹é¢ (V14.9)
# ===========================
st.set_page_config(page_title="V14.9 AI æŠ•è³‡é¡§å• (è€å¿ƒç‰ˆ)", page_icon="ğŸ›¡ï¸", layout="wide")
st.markdown("""<style>.source-tag { padding: 3px 6px; border-radius: 4px; font-size: 11px; margin-right: 5px; color: white; display: inline-block; }.news-row { margin-bottom: 8px; padding: 4px; border-bottom: 1px solid #333; font-size: 14px; }.stock-check { background-color: #262730; padding: 10px; border-radius: 5px; border: 1px solid #4b4b4b; text-align: center; margin-bottom: 15px; }.stock-name-text { font-size: 24px; font-weight: bold; color: #4CAF50; }</style>""", unsafe_allow_html=True)

st.title("ğŸ›¡ï¸ V14.9 è‚¡å¸‚å…¨è¦–è§’ç†±åº¦å„€ (è€å¿ƒç­‰å¾…ç‰ˆ)")

# è‡ªå‹•åŒæ­¥
if 'stock_dict' not in st.session_state:
    with st.spinner("ğŸš€ æ­£åœ¨å•Ÿå‹•å¤©ç¶²ï¼šåŒæ­¥ 2026 å…¨å¸‚å ´è‚¡ç¥¨æ¸…å–®..."):
        stock_dict, count = asyncio.run(sync_market_data())
        st.session_state.stock_dict = stock_dict
        st.success(f"âœ… è³‡æ–™åº«å°±ç·’ï¼š{count} æª”è‚¡ç¥¨")
        time.sleep(1) 

with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    user_input = st.text_input("è¼¸å…¥è‚¡ç¥¨ (å¦‚ 2330 æˆ– ç·¯å‰µ)", value="2330")
    
    st.markdown("---")
    st.subheader("ğŸ§  AI å¤§è…¦")
    
    active_key = None
    if SYSTEM_API_KEY:
        st.success("âœ… ç³»çµ±é‡‘é‘°å·²è¼‰å…¥ (éš±è—ä¿è­·ä¸­)")
        active_key = SYSTEM_API_KEY
    else:
        user_key = st.text_input("Gemini API Key", type="password", placeholder="æœªæª¢æ¸¬åˆ°ç³»çµ± Keyï¼Œè«‹æ‰‹å‹•è¼¸å…¥")
        if user_key: active_key = user_key
        else: st.caption("âš ï¸ ä½¿ç”¨å‚™ç”¨é—œéµå­—ç®—æ³•")
    
    if user_input:
        if 'last_input' not in st.session_state or st.session_state.last_input != user_input:
            code, name = asyncio.run(resolve_stock_info(user_input, st.session_state.stock_dict))
            if code:
                st.session_state.target_code = code
                st.session_state.target_name = name
                st.session_state.last_input = user_input
            else:
                st.session_state.target_code = None; st.session_state.target_name = None

        if st.session_state.get('target_code'):
            st.markdown(f"<div class='stock-check'><div class='stock-name-text'>{st.session_state.target_name}</div><div>({st.session_state.target_code})</div></div>", unsafe_allow_html=True)
        else: st.markdown(f"<div class='stock-check' style='color:#ff4757'>âš ï¸ æ‰¾ä¸åˆ°ç›®æ¨™</div>", unsafe_allow_html=True)
    
    run_btn = st.button("ğŸš€ å•Ÿå‹• AI åˆ†æ", type="primary", disabled=not st.session_state.get('target_code'))

if run_btn:
    target_code = st.session_state.get('target_code')
    target_name = st.session_state.get('target_name')
    
    status = st.empty(); bar = st.progress(0)
    status.text(f"ğŸ” çˆ¬èŸ²å‡ºå‹•ï¼šæ­£åœ¨æœé›† {target_name} çš„å…¨ç¶²æ–°èæ‘˜è¦...")
    bar.progress(10)
    
    results = asyncio.run(run_analysis(target_code))
    bar.progress(60)
    
    all_news = []
    source_names = ["é‰…äº¨ç¶²", "Yahoo", "ç¶“æ¿Ÿæ—¥å ±", "è‡ªç”±è²¡ç¶“", "å·¥å•†æ™‚å ±", "ä¸­æ™‚æ–°è", "ETtoday", "TVBSæ–°è", "ä»Šå‘¨åˆŠ", "è²¡è¨Š", "é¢¨å‚³åª’"]
    data_map = {name: res for name, res in zip(source_names, results)}
    for name, data in data_map.items():
        all_news.extend(data)
    
    final_score = 0
    ai_report = ""
    used_model = "None"
    
    if active_key and all_news:
        status.text("ğŸ§  AI æ­£åœ¨æƒæå¯ç”¨æ¨¡å‹ä¸¦æ’°å¯«å ±å‘Š...")
        bar.progress(80)
        # ä½¿ç”¨ Requests ç‰ˆå‡½æ•¸ (å·²èª¿æ•´ Timeout ç‚º 60ç§’)
        ai_score, ai_report, used_model = analyze_with_gemini_requests(active_key, target_name, all_news)
        
        if ai_score:
            final_score = ai_score
        else:
            st.warning(f"AI é€£ç·šå¤±æ•— ({ai_report})ï¼Œè½‰ç‚ºå‚™ç”¨ç®—æ³•")
            total = 0; count = 0
            for name, data in data_map.items():
                s, _ = calculate_score_keyword(data, name)
                if data: total += s; count += 1
            final_score = round(total/count, 1) if count else 0
            
    else:
        status.text("âš¡ æ­£åœ¨é€²è¡Œé—œéµå­—+æ‘˜è¦æ¬Šé‡è¨ˆç®—...")
        bar.progress(80)
        total = 0; count = 0
        all_signals = []
        for name, data in data_map.items():
            s, r = calculate_score_keyword(data, name)
            all_signals.extend(r)
            if data: total += s; count += 1
        final_score = round(total/count, 1) if count else 0
        ai_report = f"### é—œéµå­—è¨Šè™Ÿ\n{', '.join(list(set(all_signals))[:15])}"

    bar.progress(100); time.sleep(0.5); status.empty(); bar.empty()

    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.metric("ç¶œåˆè©•åˆ†", f"{final_score} åˆ†", f"{len(all_news)} å‰‡æ–°è")
        if final_score >= 75: l, c = "ğŸ”¥ğŸ”¥ğŸ”¥ æ¥µåº¦æ¨‚è§€", "#ff4757"
        elif final_score >= 60: l, c = "ğŸ”¥ åå¤šçœ‹å¾…", "#ffa502"
        elif final_score <= 40: l, c = "ğŸ§Š åç©ºä¿å®ˆ", "#5352ed"
        else: l, c = "âš–ï¸ ä¸­ç«‹éœ‡ç›ª", "#747d8c"
        st.markdown(f"<h2 style='color:{c}'>{l}</h2>", unsafe_allow_html=True)
        if used_model != "None":
            st.caption(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {used_model}")
        
        st.divider()
        st.subheader("æ–°èä¾†æºåˆ†å¸ƒ")
        for name, data in data_map.items():
            if data: st.caption(f"{name}: {len(data)} å‰‡")

    with col2:
        if active_key and "SCORE:" in ai_report:
            st.subheader("ğŸ¤– AI æŠ•è³‡åˆ†æå ±å‘Š")
            clean_report = ai_report.replace("SCORE:", "").strip()
            st.info(clean_report)
        else:
            st.subheader("ğŸ“Š é—œéµå­—åˆ†æçµæœ")
            st.write(ai_report)
            
        st.divider()
        st.subheader("ğŸ“° ç²¾é¸æ–°èæ‘˜è¦")
        if all_news:
            for n in all_news[:15]:
                snippet = n.get('snippet', 'ç„¡æ‘˜è¦')
                if len(snippet) > 50: snippet = snippet[:50] + "..."
                st.markdown(f"""
                <div class='news-row'>
                    <b>[{n['source']}]</b> <a href='https://www.google.com/search?q={n['title']}' target='_blank'>{n['title']}</a><br>
                    <small style='color:#aaa'>{snippet}</small>
                </div>
                """, unsafe_allow_html=True)
        else: st.info("ç„¡æ–°èè³‡æ–™")